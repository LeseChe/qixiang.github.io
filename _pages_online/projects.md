---
title: "Projects"
layout: archive
permalink: /projects/
---

<style>
a:link, a:visited {
  text-decoration: none;
}

a:hover, a:active {
  text-decoration: underline;
}
</style>

## Industry Projects
  - **Robust anomaly detection in human-centric videos**
    - **Duration:** 01/01/2024 - 30/06/2024
    - **Research Grant:** The NCI National AI Flagship Merit Allocation Scheme
    - **Objective:** This project aims at developing advanced computer vision and deep learning techniques to identify and characterise anomalies in video data where humans are central. The project leverages cutting-edge technology to enhance security, safety, and surveillance systems, making them more effective in detecting unusual behaviours and events, which may range from security breaches and accidents to rare medical conditions in healthcare applications.
    - **Achievements:**
      The significance of this project lies in its unique focus on human-centric videos. While anomaly detection in videos is an established field, the novelty emerges from its specialised applications in situations where human activity is central. The innovative aspects include (i) Robustness: The project seeks to develop highly reliable models capable of detecting anomalies in complex, real-world scenarios, where human interactions and activities can vary significantly. (ii) Real-time analysis: By applying these methods to real-time video streams, the project addresses the demand for timely responses to anomalies in security, industrial, and healthcare settings. (iii) Ethical considerations: The project incorporates ethical considerations, such as ensuring privacy and avoiding bias in the identification of anomalies, thereby making the technology responsible and trustworthy.

## Academic Projects
  - **Action Recognition in Videos**
    - **Duration:** 20/11/2023 - Present
    - **Supervisor:** [Dr. Lei Wang](https://leiwangr.github.io/)
    - **Objective:** This project focuses on the application of deep learning techniques for the purpose of action recognition in videos. The goal is to develop a model that can accurately identify the actions performed in a video, such as walking, running, and jumping.
  - **A closer look at finegrained motions**
    - **Duration:** 20/11/2023 - Present
    - **Supervisor:** [Dr. Lei Wang](https://leiwangr.github.io/)
    - **Objective:** For this project, we aim to develop a model that can accurately identify the fine-grained motions performed in a video. 

## Completed Projects

- **Vehicle Image Translation: Adapting Synthetic Styles to Real-World Scenarios**
  - **Duration:** S2, 2023
  - **Objective:** This project focuses on the application of Generative Adversarial Networks (GANs), specifically CycleGAN, for the purpose of image-to-image translation. The goal is to stylistically adapt vehicle images from the synthetic Vehicle-X dataset to resemble those in the real-world VeRi dataset, enhancing the robustness and accuracy of vehicle recognition algorithms.
  - **Achievements:**
    - Successfully trained a CycleGAN model to transform the style of Vehicle-X images to align with VeRi dataset aesthetics.
    - Improved the domain adaptation for vehicle recognition tasks in varied lighting and environmental conditions.
  - **Resources:** [GitHub](https://github.com/q1xiangchen/CycleGAN_vehicle), [Report](/files/I2I_report.pdf) (Feel free to explore the code repository for a deeper understanding of the methodologies applied and the results obtained)